{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22c75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c28ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40edf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef996aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e37fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"llama3-8b-8192\", groq_api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900ff42",
   "metadata": {},
   "source": [
    "# prompts and prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274fcff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ve got a curious tale about LLaMA, a type of AI model developed by Meta AI!\\n\\nIt was a typical day at the Meta AI lab when a team of researchers decided to test the limits of their latest LLaMA model. They fed it a series of seemingly unrelated prompts, hoping to see how well it could generate coherent and creative responses.\\n\\nOne of the prompts was: \"Imagine a world where cats can speak human language, but only if they\\'re wearing a specific type of hat.\"\\n\\nThe LLaMA model went to work, processing the prompt and generating a response. To the researchers\\' surprise, the model produced a short story that was not only coherent but also delightfully absurd.\\n\\nIn this feline world, the cats had developed a peculiar obsession with top hats. They would spend hours trying on different styles, from fancy silk numbers to more practical felt caps. The cats would gather in secret underground clubs, where they would discuss the finer points of hat-making and debate the best way to tie a bow tie (or, in this case, a cat-tye).\\n\\nBut here\\'s the curious part: the LLaMA model didn\\'t stop at the story. It began to generate new prompts, based on the world it had created. For example, \"What\\'s the most popular flavor of catnip among top-hatted felines?\" or \"How do cats use their hats to communicate with humans?\"\\n\\nThe researchers were amazed by the model\\'s ability to generate not only creative content but also a sense of internal logic and consistency. It was as if the LLaMA model had become a kind of feline aficionado, lost in the whimsical world it had created.\\n\\nAs they continued to experiment with the model, the researchers began to wonder: what other secrets might be hidden within the vast, uncharted territories of LLaMA\\'s imagination?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate.from_template(\n",
    "    \"tell me a {adjective} story about {topic}\"\n",
    ")\n",
    "\n",
    "llmmodelprompt=prompt_template.format(\n",
    "    adjective=\"curious\",\n",
    "    topic=\"langchain\"\n",
    ")\n",
    "\n",
    "llm.invoke(llmmodelprompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8e072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(\"what is langchain\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4939037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is a cutting-edge AI model that has been making waves in the tech community lately. LangChain is a type of large language model (LLM) that is designed to generate human-like text based on the input it receives.\\n\\nHere are some key features and capabilities of LangChain:\\n\\n1. **Language understanding**: LangChain is capable of understanding natural language and generating text that is coherent, fluent, and contextually relevant.\\n2. **Contextual understanding**: LangChain can understand the context in which the input is provided, allowing it to generate text that is tailored to the specific situation or scenario.\\n3. **Long-form text generation**: LangChain is designed to generate long-form text, such as articles, stories, or even entire books.\\n4. **Conversational dialogue**: LangChain can engage in conversational dialogue, responding to prompts and following the flow of conversation.\\n5. **Multitasking**: LangChain can perform multiple tasks simultaneously, such as generating text while also answering questions or summarizing information.\\n\\nLangChain is trained on massive datasets of text, including books, articles, and online content. This training process enables the model to learn patterns, relationships, and nuances of language, allowing it to generate text that is both informative and engaging.\\n\\nSome potential applications of LangChain include:\\n\\n1. **Content creation**: LangChain can be used to generate content for blogs, articles, social media, and other online platforms.\\n2. **Chatbots and virtual assistants**: LangChain can be integrated into chatbots and virtual assistants to enable more conversational and human-like interactions.\\n3. **Language translation**: LangChain can be used to translate text from one language to another, with the potential to improve accuracy and fluency.\\n4. **Summarization and analysis**: LangChain can be used to summarize long documents, articles, or even entire books, and provide insights and analysis.\\n\\nHowever, it's important to note that LangChain, like any AI model, is not without its limitations and potential drawbacks. For example, it may struggle with understanding nuances of language, cultural references, or context-specific knowledge. Additionally, the model's output may require human review and editing to ensure accuracy and quality.\\n\\nOverall, LangChain is an exciting development in the field of AI and natural language processing, with the potential to revolutionize the way we interact with language and generate content.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093c7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "message=template.format_messages(\n",
    "    name='Raghav',\n",
    "    user_input=\"tell me about the llm\"\n",
    ")\n",
    "\n",
    "response=llm.invoke(message).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e5b9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're referring to Large Language Models (LLMs)!\\n\\nLarge Language Models are a type of artificial intelligence designed to process and generate human-like language. They're trained on vast amounts of text data, which enables them to learn the patterns, structures, and relationships within language.\\n\\nLLMs are typically built using neural networks, a type of machine learning architecture. They're composed of multiple layers of interconnected nodes, known as neurons, which process and transform the input data. As the model is trained, the neural networks learn to represent language in a way that's similar to how humans understand it.\\n\\nSome key characteristics of LLMs include:\\n\\n1. **Scalability**: LLMs can process and generate vast amounts of text, making them useful for applications like language translation, text summarization, and chatbots.\\n2. **Contextual understanding**: LLMs can understand the context in which language is being used, allowing them to generate more accurate and relevant responses.\\n3. **Flexibility**: LLMs can be fine-tuned for specific tasks, such as language translation, sentiment analysis, or text classification.\\n4. **Creativity**: LLMs can generate novel language, including poetry, stories, and even entire conversations.\\n\\nSome examples of LLMs include:\\n\\n1. BERT (Bidirectional Encoder Representations from Transformers)\\n2. ROBERTA (Robustly Optimized BERT Pretraining Approach)\\n3. XLNet\\n4. Transformers\\n\\nLLMs have many applications in areas like:\\n\\n1. Natural Language Processing (NLP)\\n2. Text-to-Text Generation\\n3. Language Translation\\n4. Sentiment Analysis\\n5. Chatbots\\n6. Voice Assistants\\n\\nI hope that helps you understand Large Language Models better!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13568c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3ffbf98",
   "metadata": {},
   "source": [
    "# chains-steps of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aabe1238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're referring to the Large Language Model (LLM)? I'm happy to help!\\n\\nAn LLM is a type of artificial intelligence (AI) model that's specifically designed to process and generate human-like language. These models are trained on vast amounts of text data, which enables them to learn patterns, relationships, and semantics within language.\\n\\nSome key characteristics of LLMs include:\\n\\n1. **Scale**: LLMs are typically trained on massive datasets, often comprising hundreds of millions or even billions of words.\\n2. **Complexity**: LLMs can process complex language structures, such as syntax, semantics, and pragmatics.\\n3. **Contextual understanding**: LLMs can comprehend context, allowing them to generate responses that are relevant and appropriate.\\n4. **Flexibility**: LLMs can be fine-tuned for specific tasks, such as language translation, text summarization, or even chatbot applications.\\n5. **Autoregressive**: LLMs predict the next word or character in a sequence, allowing them to generate text, sentences, or even entire documents.\\n\\nLLMs have numerous applications, including:\\n\\n1. **Natural Language Processing (NLP)**: LLMs are used in NLP tasks, such as language translation, sentiment analysis, and text classification.\\n2. **Chatbots**: LLMs can be used to power conversational AI, enabling chatbots to understand and respond to user queries.\\n3. **Content creation**: LLMs can generate text, such as articles, blog posts, or even entire books.\\n4. **Research**: LLMs can be used to analyze large datasets, identify patterns, and gain insights into language and its evolution.\\n\\nSome notable examples of LLMs include:\\n\\n1. **BERT** (Bidirectional Encoder Representations from Transformers): Developed by Google, BERT is a popular LLM that's been fine-tuned for various NLP tasks.\\n2. **RoBERTa** (Robustly Optimized BERT Pretraining Approach): Developed by Microsoft, RoBERTa is another widely used LLM that's been fine-tuned for various NLP tasks.\\n3. ** transformer-XL**: Developed by Google, transformer-XL is a long-range dependency LLM that's designed to process longer sequences of text.\\n\\nThese are just a few examples of the many LLMs available. If you have any specific questions or would like to know more about a particular LLM, feel free to ask!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 502, 'prompt_tokens': 59, 'total_tokens': 561, 'completion_time': 0.672046938, 'prompt_time': 0.008527745, 'queue_time': 0.048013845, 'total_time': 0.680574683}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_24ec19897b', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--9b9c6564-c5e9-440c-9bb9-2d3724b022c5-0' usage_metadata={'input_tokens': 59, 'output_tokens': 502, 'total_tokens': 561}\n"
     ]
    }
   ],
   "source": [
    "# langchain expression language\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain=template | llm\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"name\": \"Raghav\",\n",
    "    \"user_input\": \"tell me about the llm\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd7f70",
   "metadata": {},
   "source": [
    "# output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e626156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'New Delhi'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers in JSON format.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "parser = SimpleJsonOutputParser()\n",
    "\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# Step 5: Invoke the chain with input\n",
    "response = chain.invoke({\n",
    "    \"question\": \"What is the capital of India? Please respond in JSON with 'answer' as key.\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2db4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
