{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0cd5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a1e1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c2bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba681bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990eb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"llama3-8b-8192\", groq_api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "543c731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(\"what is langchain\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ca0220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source AI model developed by the LangChain AI research team, which is a sub-group of the well-known AI research organization, EleutherAI. LangChain is a large-scale language model that has been trained on a massive dataset of text and has been designed to generate human-like language.\n",
      "\n",
      "LangChain is often referred to as a \"next-generation\" language model because it has been trained using a more advanced technology called transformer architecture, which allows it to understand and generate text in a more nuanced and context-dependent way. This means that LangChain can generate more sophisticated and realistic text that is tailored to specific contexts and topics.\n",
      "\n",
      "Some of the key features of LangChain include:\n",
      "\n",
      "1. **Large scale**: LangChain has been trained on a massive dataset of over 175 billion parameters, making it one of the largest language models in the world.\n",
      "2. **Transformer architecture**: LangChain uses the transformer architecture, which is a type of neural network that is particularly well-suited for natural language processing tasks.\n",
      "3. **Contextual understanding**: LangChain is designed to understand the context in which language is being used, which allows it to generate more accurate and relevant text.\n",
      "4. **Multimodal capabilities**: LangChain can generate text that is accompanied by images, audio, or other forms of media, making it a versatile tool for a wide range of applications.\n",
      "5. **Open-source**: LangChain is an open-source model, which means that developers can access and modify the code to suit their specific needs.\n",
      "\n",
      "Some potential applications of LangChain include:\n",
      "\n",
      "1. **Natural language processing**: LangChain can be used for a wide range of natural language processing tasks, such as language translation, text summarization, and sentiment analysis.\n",
      "2. **Content generation**: LangChain can be used to generate high-quality content, such as articles, blog posts, and social media updates.\n",
      "3. **Chatbots and virtual assistants**: LangChain can be used to power chatbots and virtual assistants that can understand and respond to user input in a more natural and human-like way.\n",
      "4. **Language learning**: LangChain can be used to help language learners by providing them with realistic and contextual language practice.\n",
      "\n",
      "Overall, LangChain is a powerful and versatile AI model that has the potential to revolutionize the way we use language and communicate with each other.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b00e0048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an AI-powered language understanding and generation platform that uses a combination of natural language processing (NLP) and machine learning algorithms to analyze and generate human-like language. The platform is designed to enable developers and businesses to build more sophisticated language-based applications, such as chatbots, virtual assistants, and language translation systems.\n",
      "\n",
      "LangChain's technology is based on a technique called \"language modeling,\" which involves training a neural network on a large corpus of text data to learn the patterns and structures of language. This allows the platform to generate text that is coherent, natural-sounding, and tailored to a specific context or topic.\n",
      "\n",
      "Some of the key features of LangChain include:\n",
      "\n",
      "1. **Language understanding**: LangChain's NLP capabilities allow it to analyze and interpret human language, including sentiment, intent, and context.\n",
      "2. **Text generation**: The platform can generate text in a variety of styles, formats, and tones, from short responses to longer pieces of content.\n",
      "3. **Conversational AI**: LangChain's technology enables the development of conversational AI applications, such as chatbots and virtual assistants, that can engage with users in natural language.\n",
      "4. **Language translation**: The platform can translate text from one language to another, with a focus on preserving the original meaning and context.\n",
      "5. **Customization**: LangChain's API allows developers to customize the platform's language understanding and generation capabilities to fit their specific needs and use cases.\n",
      "\n",
      "LangChain's applications are diverse and can be used in various industries, such as:\n",
      "\n",
      "1. **Customer service**: LangChain's conversational AI capabilities can be used to build chatbots and virtual assistants that provide customer support and answer frequently asked questions.\n",
      "2. **Content creation**: The platform's text generation capabilities can be used to generate content, such as blog posts, articles, and social media updates, at scale and speed.\n",
      "3. **Marketing and advertising**: LangChain's language understanding and generation capabilities can be used to analyze and generate targeted marketing messages, product descriptions, and advertising copy.\n",
      "4. **Language learning**: The platform's language translation capabilities can be used to develop language learning applications and resources, such as language translation software and language learning platforms.\n",
      "\n",
      "Overall, LangChain is a powerful AI-powered language understanding and generation platform that has the potential to transform the way we interact with language and use it in various applications."
     ]
    }
   ],
   "source": [
    "#streaming output like chatgpt\n",
    "for chunk in llm.stream(\"what is langchain\"):\n",
    "    print(chunk.content,end='',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cb1be",
   "metadata": {},
   "source": [
    "# Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97116dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "964d3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is quantum computing?\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb3a349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is a new paradigm in computing that uses the principles of quantum mechanics to perform calculations and operations on data. Unlike classical computers, which use bits (0s and 1s) to process information, quantum computers use quantum bits or qubits.\n",
      "\n",
      "Qubits are unique because they can exist in multiple states simultaneously, known as a superposition. This means that a qubit can represent not just 0 or 1, but also any combination of 0 and 1, such as 0.5 or 0.75. This property allows quantum computers to process multiple possibilities at the same time, making them incredibly powerful for certain types of calculations.\n",
      "\n",
      "Quantum computers can perform certain calculations much faster than classical computers, particularly in areas such as:\n",
      "\n",
      "1. Cryptography: Quantum computers can break certain encryption algorithms much faster than classical computers, but they can also create new, quantum-resistant encryption methods.\n",
      "2. Optimization: Quantum computers can solve complex optimization problems, such as finding the shortest path between two points, much faster than classical computers.\n",
      "3. Machine learning: Quantum computers can be used to speed up machine learning algorithms, such as neural networks, by processing large amounts of data more efficiently.\n",
      "4. Simulation: Quantum computers can simulate complex quantum systems, such as molecules and materials, which could lead to breakthroughs in fields like chemistry and materials science.\n",
      "\n",
      "Quantum computing is still a relatively new and developing field, and there are many challenges to overcome before quantum computers can be widely used. However, many organizations and companies are working to develop and improve quantum computing technology, and it's expected to have a significant impact on many fields in the future.\n",
      "\n",
      "Some of the key players in the quantum computing space include:\n",
      "\n",
      "* IBM Quantum: A cloud-based quantum computing platform that provides access to quantum computers and quantum algorithms.\n",
      "* Google Quantum AI Lab: A research organization that develops quantum algorithms and applications.\n",
      "* Microsoft Quantum: A quantum computing platform that provides tools and software for developing and running quantum applications.\n",
      "* Rigetti Computing: A cloud-based quantum computing platform that provides access to quantum computers and quantum algorithms.\n",
      "\n",
      "These are just a few examples, and there are many other organizations and companies working on quantum computing technology.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "796f55a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'completion_tokens': 444, 'prompt_tokens': 26, 'total_tokens': 470, 'completion_time': 0.575697268, 'prompt_time': 0.004796724, 'queue_time': 0.044671466, 'total_time': 0.580493992}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_24ec19897b', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21f1eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01611337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12152\\4004604031.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$defs': {'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9\\n\\nMay also hold extra provider-specific keys.',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'additionalProperties': True, 'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'additionalProperties': True,\n",
       " 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       " 'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "    {'items': {'anyOf': [{'type': 'string'},\n",
       "       {'additionalProperties': True, 'type': 'object'}]},\n",
       "     'type': 'array'}],\n",
       "   'title': 'Content'},\n",
       "  'additional_kwargs': {'additionalProperties': True,\n",
       "   'title': 'Additional Kwargs',\n",
       "   'type': 'object'},\n",
       "  'response_metadata': {'additionalProperties': True,\n",
       "   'title': 'Response Metadata',\n",
       "   'type': 'object'},\n",
       "  'type': {'const': 'ai', 'default': 'ai', 'title': 'Type', 'type': 'string'},\n",
       "  'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Name'},\n",
       "  'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Id'},\n",
       "  'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "  'tool_calls': {'default': [],\n",
       "   'items': {'$ref': '#/$defs/ToolCall'},\n",
       "   'title': 'Tool Calls',\n",
       "   'type': 'array'},\n",
       "  'invalid_tool_calls': {'default': [],\n",
       "   'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "   'title': 'Invalid Tool Calls',\n",
       "   'type': 'array'},\n",
       "  'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None}},\n",
       " 'required': ['content'],\n",
       " 'title': 'AIMessage',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2386560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
